{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qv8ix1ytqhy",
        "outputId": "feda47dd-7638-4f80-edcd-cc83ec52a9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "URjk-GQCtxvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Implement a Function to Define the Prompt.\n",
        "\n",
        "def define_prompt(text):\n",
        "  \"\"\"\n",
        "  Defines a prompt string based on the input text.\n",
        "\n",
        "  Args:\n",
        "    text: The input string to be included in the prompt.\n",
        "\n",
        "  Returns:\n",
        "    A string representing the prompt.\n",
        "  \"\"\"\n",
        "  return f\"Complete the following sentence: {text}\"\n"
      ],
      "metadata": {
        "id": "nztCd4Z6utao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Edit this function to properly call the OpenAI API to get ChatGPT's Response.\n",
        "\n",
        "# Make sure to replace \"YOUR_API_KEY\" with your actual OpenAI API key\n",
        "openai.api_key = \"YOUR_API_KEY\"\n",
        "\n",
        "def get_chatgpt_response(prompt):\n",
        "  \"\"\"\n",
        "  Gets a response from the OpenAI ChatGPT model.\n",
        "\n",
        "  Args:\n",
        "    prompt: The input prompt string.\n",
        "\n",
        "  Returns:\n",
        "    The text of the response from ChatGPT, or None if an error occurs.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    response = openai.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",  # You can choose a different model like \"gpt-4\"\n",
        "      messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "# input_text = \"The quick brown fox jumps over\"\n",
        "# prompt_text = define_prompt(input_text)\n",
        "# chatgpt_output = get_chatgpt_response(prompt_text)\n",
        "# if chatgpt_output:\n",
        "#   print(chatgpt_output)"
      ],
      "metadata": {
        "id": "1aPT3td7vFxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Call the get_chatgpt_response(prompt): function to get the ChatGPT prompt.\n",
        "\n",
        "prompt = \"What is the capital of France?\"\n",
        "chatgpt_output = get_chatgpt_response(prompt)\n",
        "if chatgpt_output:\n",
        "  chatgpt_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzkwS8NrvYkS",
        "outputId": "305d2c6d-bef6-455b-aa56-4ee474fb50cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Get the LinkedIn post from the user.\n",
        "\n",
        "def get_linkedin_post_from_user() -> str:\n",
        "    \"\"\"\n",
        "    Prompts the user to input a LinkedIn post, supporting multi-line input.\n",
        "    Input ends when the user types 'END' on a new line.\n",
        "\n",
        "    Returns:\n",
        "        str: The full LinkedIn post as entered by the user.\n",
        "    \"\"\"\n",
        "    print(\"Please paste your LinkedIn post below.\")\n",
        "    print(\"Type 'END' on a new line when you're done:\\n\")\n",
        "\n",
        "    lines = []\n",
        "    while True:\n",
        "        line = input()\n",
        "        if line.strip().upper() == \"END\":\n",
        "            break\n",
        "        lines.append(line)\n",
        "\n",
        "    return \"\\n\".join(lines)\n"
      ],
      "metadata": {
        "id": "b8UC6BRPwQGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Get OpenAI API Key here from the user.\n",
        "\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# Get OpenAI API Key from user input\n",
        "openai_api_key = input(\"Enter your OpenAI API key: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\")\n",
        "openai.api_key = openai_api_key"
      ],
      "metadata": {
        "id": "MAgsSBpgx7ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Define the variable by asking user input\n",
        "openai_api_key = input(\"Please enter your OpenAI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVBwN9n27H31",
        "outputId": "e7496639-2517-4cdb-91db-e2320461881c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your OpenAI API key: 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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Now create the OpenAI client using that variable\n",
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "MTwOyaL77npD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Call get_insights_from_chatgpt function with a client and a LinkedIn post.\n",
        "\n",
        "def get_insights_from_chatgpt(client, linkedin_post: str):\n",
        "    \"\"\"\n",
        "    Gets insights from ChatGPT about a given LinkedIn post using an OpenAI client.\n",
        "\n",
        "    Args:\n",
        "        client: An initialized OpenAI client.\n",
        "        linkedin_post: The text content of the LinkedIn post.\n",
        "\n",
        "    Returns:\n",
        "        The text of the response from ChatGPT providing insights, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    prompt = f\"Provide some insights and feedback on the following LinkedIn post:\\n\\n{linkedin_post}\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",  # Or a different model like \"gpt-4\"\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while getting insights: {e}\")\n",
        "        return None\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "# Assuming openai_api_key is already set in the previous code block\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# Get the LinkedIn post from the user\n",
        "linkedin_post = get_linkedin_post_from_user()\n",
        "\n",
        "# Call the function to get insights\n",
        "insights = get_insights_from_chatgpt(client, linkedin_post)\n",
        "\n",
        "if insights:\n",
        "    print(\"\\nInsights from ChatGPT:\")\n",
        "    print(insights)\n",
        "else:\n",
        "    print(\"\\nCould not get insights from ChatGPT.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cmNYjdzYyGIc",
        "outputId": "0aa35f9e-0fe2-4864-c79b-49d2c4f1d820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_linkedin_post_from_user' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-4144096179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Get the LinkedIn post from the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mlinkedin_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linkedin_post_from_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Call the function to get insights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_linkedin_post_from_user' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Ask user for the API key\n",
        "openai_api_key = input(\"Please enter your OpenAI API key: \")\n",
        "\n",
        "# Create the client\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# Just confirm setup\n",
        "print(\"✅ OpenAI client is ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Vf_IrQ8M5I",
        "outputId": "bb3690a1-7489-466a-b879-c343f9483e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your OpenAI API key: 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\n",
            "✅ OpenAI client is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "1e7d8825",
        "outputId": "e5a5415d-a5b3-41c5-9377-049238531b51"
      },
      "source": [
        "# Execute the cell defining get_linkedin_post_from_user by its ID\n",
        "get_ipython().run_cell_id('b8UC6BRPwQGX')\n",
        "\n",
        "# Re-execute the cell to get insights now that the function is defined by its ID\n",
        "get_ipython().run_cell_id('cmNYjdzYyGIc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Shell' object has no attribute 'run_cell_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-538126296.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Execute the cell defining get_linkedin_post_from_user by its ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b8UC6BRPwQGX'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Re-execute the cell to get insights now that the function is defined by its ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cmNYjdzYyGIc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Shell' object has no attribute 'run_cell_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1985fab",
        "outputId": "a8b61577-997a-4d64-9130-ac24a93404ab"
      },
      "source": [
        "# Define the function to get LinkedIn post from the user\n",
        "def get_linkedin_post_from_user() -> str:\n",
        "    \"\"\"\n",
        "    Prompts the user to input a LinkedIn post, supporting multi-line input.\n",
        "    Input ends when the user types 'END' on a new line.\n",
        "\n",
        "    Returns:\n",
        "        str: The full LinkedIn post as entered by the user.\n",
        "    \"\"\"\n",
        "    print(\"Please paste your LinkedIn post below.\")\n",
        "    print(\"Type 'END' on a new line when you're done:\\n\")\n",
        "\n",
        "    lines = []\n",
        "    while True:\n",
        "        line = input()\n",
        "        if line.strip().upper() == \"END\":\n",
        "            break\n",
        "        lines.append(line)\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Define the function to get insights from ChatGPT\n",
        "def get_insights_from_chatgpt(client, linkedin_post: str):\n",
        "    \"\"\"\n",
        "    Gets insights from ChatGPT about a given LinkedIn post using an OpenAI client.\n",
        "\n",
        "    Args:\n",
        "        client: An initialized OpenAI client.\n",
        "        linkedin_post: The text content of the LinkedIn post.\n",
        "\n",
        "    Returns:\n",
        "        The text of the response from ChatGPT providing insights, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    prompt = f\"Provide some insights and feedback on the following LinkedIn post:\\n\\n{linkedin_post}\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",  # Or a different model like \"gpt-4\"\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while getting insights: {e}\")\n",
        "        return None\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "# Assuming openai_api_key is already set in a previous code block\n",
        "# If not, you might need to add a line here to get the API key again\n",
        "# from openai import OpenAI\n",
        "# client = OpenAI(api_key=openai_api_key) # Uncomment and modify if needed\n",
        "\n",
        "# Get the LinkedIn post from the user\n",
        "linkedin_post = get_linkedin_post_from_user()\n",
        "\n",
        "# Call the function to get insights\n",
        "insights = get_insights_from_chatgpt(client, linkedin_post)\n",
        "\n",
        "if insights:\n",
        "    print(\"\\nInsights from ChatGPT:\")\n",
        "    print(insights)\n",
        "else:\n",
        "    print(\"\\nCould not get insights from ChatGPT.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please paste your LinkedIn post below.\n",
            "Type 'END' on a new line when you're done:\n",
            "\n",
            "About the Role: We are looking for an experienced and passionate Spirits & Wine Shop Manager to lead our retail business and elevate the customer experience in our premium beverage store. This is a hands-on leadership role, ideal for someone with a deep appreciation for fine spirits—especially whisky and rum—and a proven record in retail sales and customer service.\n",
            "END\n",
            "\n",
            "Insights from ChatGPT:\n",
            "1. The post effectively communicates the specific qualifications and experience required for the role, making it clear that the ideal candidate must have a strong understanding and passion for spirits, particularly whisky and rum.\n",
            "\n",
            "2. The emphasis on customer experience and retail sales indicates that the company values a high level of customer service and is looking for someone who can enhance the overall store experience for customers.\n",
            "\n",
            "3. The mention of it being a hands-on leadership role suggests that the company is seeking a proactive and engaged manager who is willing to roll up their sleeves and actively lead the team.\n",
            "\n",
            "4. The post could potentially be improved by providing more details on the specific responsibilities and challenges of the role, as well as any unique opportunities for growth and development within the company.\n",
            "\n",
            "5. Overall, the post effectively targets a specific audience of experienced and passionate individuals in the spirits and wine industry, making it likely to attract the right candidates for the position.\n"
          ]
        }
      ]
    }
  ]
}